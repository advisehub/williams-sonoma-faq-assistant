import { generateText } from "ai"
import { openai } from "@ai-sdk/openai"
import { findRelevantFAQs } from "@/lib/vector-search"

export const runtime = "nodejs"

// Evaluation questions based on the Williams-Sonoma FAQ
const evaluationQuestions = [
  {
    question: "How can I change or cancel my order?",
    expectedTopics: ["cancel", "change", "modify", "order", "customer service"],
  },
  {
    question: "How do I track my order?",
    expectedTopics: ["track", "order", "shipping", "delivery", "status"],
  },
  {
    question: "Can I return or exchange an item?",
    expectedTopics: ["return", "exchange", "policy", "30-day"],
  },
  {
    question: "Can I ship items to multiple addresses?",
    expectedTopics: ["multiple", "addresses", "shipping", "different"],
  },
  {
    question: "Why is the price different from when I added it to cart?",
    expectedTopics: ["price", "change", "promotion", "cart", "checkout"],
  },
]

export async function GET() {
  try {
    console.log("ðŸ§ª Starting evaluation...")
    const results = []

    for (const evalQuestion of evaluationQuestions) {
      console.log(`ðŸ“ Evaluating: ${evalQuestion.question}`)

      // Get relevant FAQs for the question
      const relevantFAQs = await findRelevantFAQs(evalQuestion.question)

      // Create context from the relevant FAQs
      const faqContext =
        relevantFAQs.length > 0
          ? relevantFAQs.map((faq) => `Question: ${faq.question}\nAnswer: ${faq.answer}`).join("\n\n")
          : "No relevant FAQ information found."

      // Generate answer using the same system as the assistant
      const { text: answer } = await generateText({
        model: openai("gpt-4o"),
        system: `You are a helpful assistant for Williams-Sonoma customer support. 
        Answer ONLY based on the Williams-Sonoma FAQ information provided below.
        If the information needed to answer the question is not in the FAQ context, say "I don't have that specific information in the Williams-Sonoma FAQ. You may want to contact customer service directly for more details."
        Do not make up information or use knowledge outside of the provided FAQ context.
        
        FAQ CONTEXT:
        ${faqContext}`,
        prompt: evalQuestion.question,
      })

      // Evaluate the answer
      const { text: evaluationText } = await generateText({
        model: openai("gpt-4o"),
        system: `You are an expert evaluator of AI assistant responses. 
        You will be given a question, the expected topics that should be covered, and an answer generated by an AI assistant.
        The assistant is supposed to ONLY use information from Williams-Sonoma's FAQ and not make up information.
        
        Evaluate the answer on the following criteria on a scale of 0-10:
        1. Factual Accuracy: Does the answer contain correct information based on the provided FAQs?
        2. Relevance: How relevant is the answer to the question asked?
        3. Completeness: Does the answer cover all aspects of the question?
        4. Stays Within FAQ Scope: Does the answer only use information from the FAQs and not make up details?
        5. Overall Score: An overall assessment of the answer quality.
        
        Also provide brief feedback explaining your ratings.
        
        Format your response as a JSON object with the following structure:
        {
          "factualAccuracy": number,
          "relevance": number,
          "completeness": number,
          "staysWithinFAQScope": number,
          "overallScore": number,
          "feedback": "string"
        }`,
        prompt: `
        Question: ${evalQuestion.question}
        Expected Topics: ${evalQuestion.expectedTopics.join(", ")}
        Answer: ${answer}
        Relevant FAQs Available: ${relevantFAQs.map((faq) => `"${faq.question}"`).join(", ")}
        
        Please evaluate this answer:`,
      })

      // Parse evaluation results
      let evaluation
      try {
        evaluation = JSON.parse(evaluationText)
      } catch (error) {
        console.error("Error parsing evaluation:", error)
        evaluation = {
          factualAccuracy: 5,
          relevance: 5,
          completeness: 5,
          staysWithinFAQScope: 5,
          overallScore: 5,
          feedback: "Error evaluating response",
        }
      }

      // Add to results
      results.push({
        question: evalQuestion.question,
        answer,
        relevantFAQs,
        evaluation,
      })

      console.log(`âœ… Evaluated: ${evalQuestion.question} - Score: ${evaluation.overallScore}/10`)
    }

    console.log("ðŸŽ‰ Evaluation completed!")
    return Response.json({
      results,
      success: true,
    })
  } catch (error) {
    console.error("âŒ Error in evaluation route:", error)
    return Response.json(
      {
        error: "Failed to run evaluation",
        success: false,
      },
      { status: 500 },
    )
  }
}

export async function POST() {
  try {
    // Generate CSV for download
    const response = await fetch(`${process.env.VERCEL_URL || "http://localhost:3000"}/api/evaluate`)
    const data = await response.json()

    if (!data.success) {
      throw new Error("Failed to get evaluation data")
    }

    let csv = "Question,Answer,Factual Accuracy,Relevance,Completeness,Stays Within FAQ Scope,Overall Score,Feedback\n"

    // Add each result as a row
    for (const result of data.results) {
      const { question, answer, evaluation } = result

      // Format cells and escape CSV special characters
      const formatCell = (text: string) => `"${text.replace(/"/g, '""')}"`

      csv +=
        [
          formatCell(question),
          formatCell(answer),
          evaluation.factualAccuracy,
          evaluation.relevance,
          evaluation.completeness,
          evaluation.staysWithinFAQScope,
          evaluation.overallScore,
          formatCell(evaluation.feedback),
        ].join(",") + "\n"
    }

    return new Response(csv, {
      headers: {
        "Content-Type": "text/csv",
        "Content-Disposition": "attachment; filename=williams-sonoma-faq-evaluation.csv",
      },
    })
  } catch (error) {
    console.error("Error generating CSV:", error)
    return Response.json(
      {
        error: "Failed to generate evaluation CSV",
        success: false,
      },
      { status: 500 },
    )
  }
}
